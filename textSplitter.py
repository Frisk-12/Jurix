#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Dec 21 22:36:25 2023

@author: andreadesogus
"""

from llama_index.langchain_helpers.text_splitter import TokenTextSplitter

def tokenSplitter():
    token_textSplitter = TokenTextSplitter(
        separator=".\n\n\n",
        backup_separators=["FATTO", "SVOLGIMENTO DEL PROCESSO", "PQM", "P.Q.M", "P . Q . M", "RAGIONI DELLA DECISIONE", "Motivi della decisione", "Ragioni della decisione", "DIRITTO", "   Diritto",
                            "\n1. ",
                            "\n2. ",
                            "\n3. ",
                            "\n4. ",
                            "\n5. ",
                            "\n6. ",
                            "\n7. ",
                            "\n8. ",
                            "\n9. ",
                            "\n10. ",
                            "\n11. ",
                            "\n12. ",
                            "\n13. ",
                            "\n14. ",
                            "\n15. ",
                            "\n16. ",
                            "\n17. ",
                            "\n18. ",
                            "\n19. ",
                            "\n20. ",
                            "\n21. ",
                            "\n22. ",
                            "\n23. ",
                            "\n24. ",
                            "\n25. ",
                            "\n26. ",
                            "\n27. ",
                            "\n28. ",
                            "\n29. ",
                            "\n30. ",
                            "\n31. ",
                            "\n32. ",
                            "\n33. ",
                            "\n34. ",
                            "\n35. ",
                            "\n\n1 ",
                            "\n\n2 ",
                            "\n\n3 ",
                            "\n\n4 ",
                            "\n\n5 ",
                            "\n\n6 ",
                            "\n\n7 ",
                            "\n\n8 ",
                            "\n9\n ",
                            "\n\n10 ",
                            "\n\n11 ",
                            "\n\n12 ",
                            "\n\n13 ",
                            "\n\n14 ",
                            "\n\n15 ",
                            "\n\n16 ",
                            "\n\n17 ",
                            "\n\n18 ",
                            "\n\n19 ",
                            "\n\n20 ",
                            "\n\n21 ",
                            "\n\n22 ",
                            "\n\n23 ",
                            "\n\n24 ",
                            "\n\n25 ",
                            "\n\n26 ",
                            "\n\n27 ",
                            "\n\n28 ",
                            "\n\n29 ",
                            "\n\n30 ",
                            "\n\n31 ",
                            "\n\n32 ",
                            "\n\n33 ",
                            "\n\n34 ",
                            "\n\n35 ",
                            "\n\n",
                            "\n \n",
                            "\n  \n",
                            ".\n   ", 
                            ".\n ", 
                            ".\n", 
                            "\n    ", 
                            "\n ",
                            "\n"
                            ". "],
        chunk_overlap=0,
        chunk_size=7500
    )
    return token_textSplitter